# Mainframe Integration - COBOL + JCL + SQLite

## Overview

The Enterprise Assistant now supports comprehensive mainframe ETL analysis through:

1. **COBOL Program Parser** - Parses COBOL programs to extract structure, data, and dependencies
2. **JCL Job Parser** - Parses JCL batch jobs to understand job orchestration and workflows
3. **SQLite Database Integration** - Sample relational databases representing modern data stores
4. **Unified Knowledge Graph** - All mainframe and database artifacts in a single queryable graph

This enables answering complex questions about mainframe ETL pipelines, data lineage, and impact analysis.

## Architecture

### Parsers

#### COBOL Parser (`cobol_parser.py`)

**Supported Files:** `.cbl`, `.cob`, `.CBL`, `.COB`

**Extracts:**
- **Program ID** - `PROGRAM-ID` from IDENTIFICATION DIVISION
- **Files** - `SELECT` statements from FILE-CONTROL → DataSource nodes
- **Data Records** - 01-level items from WORKING-STORAGE → DataEntity nodes
- **Paragraphs** - Paragraph names from PROCEDURE DIVISION → Component nodes
- **Dependencies:**
  - `PERFORM` calls → Internal execution dependencies
  - `CALL` statements → External program dependencies
  - `READ`/`WRITE` → File I/O dependencies

**Example:**
```cobol
PROGRAM-ID. CUST001.
...
FILE-CONTROL.
    SELECT CUSTOMER-FILE ASSIGN TO CUSTOMER.INPUT.MASTER.
...
PROCEDURE DIVISION.
    PERFORM 1000-INITIALIZE.
    READ CUSTOMER-FILE.
```

**Produces:**
- Package node: `CUST001`
- DataSource: `CUSTOMER.INPUT.MASTER`
- Component: `1000-INITIALIZE` (paragraph)
- Dependencies: CUST001 → CUSTOMER.INPUT.MASTER (READS_FROM)

#### JCL Parser (`jcl_parser.py`)

**Supported Files:** `.jcl`, `.JCL`, `.txt` (if starts with `//`)

**Extracts:**
- **Job Name** - `//JOBNAME JOB` statement
- **Steps** - `//STEPNAME EXEC PGM=` → Component nodes
- **Programs** - `PGM=` or `PROC=` parameters
- **Datasets** - `DD DSN=` statements → DataSource nodes
- **Dependencies:**
  - Sequential step order → PRECEDES
  - Dataset I/O → READS_FROM / WRITES_TO

**Example:**
```jcl
//DAILYSAL JOB (ACCT),'SALES BATCH'
//STEP001  EXEC PGM=SALE001
//SALINP   DD DSN=SALES.INPUT.TRANS,DISP=SHR
//SALOUT   DD DSN=SALES.OUTPUT.SALE001,DISP=(NEW,CATLG)
//STEP002  EXEC PGM=SALE002
//SALEIN   DD DSN=SALES.OUTPUT.SALE001,DISP=SHR
```

**Produces:**
- Package node: `DAILYSAL`
- Components: `step_STEP001`, `step_STEP002`
- DataSources: `SALES.INPUT.TRANS`, `SALES.OUTPUT.SALE001`
- Dependencies:
  - STEP001 → STEP002 (PRECEDES)
  - STEP001 → SALES.INPUT.TRANS (READS_FROM)
  - STEP001 → SALES.OUTPUT.SALE001 (WRITES_TO)
  - STEP002 → SALES.OUTPUT.SALE001 (READS_FROM)

### Sample Data

#### Real Mainframe Samples

From [Open Mainframe Project](https://github.com/openmainframeproject/cobol-programming-course):

**COBOL Programs:**
- `EMPPAY.CBL` - Employee payroll calculation (2.0KB)
- `DEPTPAY.CBL` - Department payroll (1.4KB)
- `CBLDB21.cbl` - DB2 access (9.1KB)
- `CBLDB22.cbl` - DB2 operations (13KB)
- `CBLDB23.cbl` - DB2 queries (12KB)

**JCL Jobs:** 20+ real batch job files

#### Synthetic Mainframe Environment

Generated by `generate_mainframe_data.py`:

**6 Business Domains:**
1. **CUSTOMER** - Customer master, validation, credit check, updates, merge/purge, reports
2. **SALES** - Extract, validation, commission, summary, forecast, tax
3. **INVENTORY** - Master update, reorder check, valuation, movement, reconciliation, aging
4. **FINANCE** - GL update, reconciliation, statements, budget reports, cash flow, tax
5. **PAYROLL** - Master load, hours validation, tax calc, check generation, deductions, reports
6. **BILLING** - Invoice generation, validation, payment processing, aging, dunning, revenue

**36 COBOL Programs:**
- 6 programs per domain
- Realistic FILE-CONTROL sections
- PROCEDURE DIVISION with paragraphs
- PERFORM and CALL dependencies
- READ/WRITE operations

**13 JCL Jobs:**
- **Daily:** DAILYCUS, DAILYSAL, DAILYINV, DAILYFIN, DAILYPAY, DAILYBIL (6 jobs)
- **Weekly:** WKLYINV, WKLYFIN, WKLYSALE (3 jobs)
- **Monthly:** MNTHPAY, MNTHFIN, MNTHBIL, MNTHCUS (4 jobs)

**Expected Graph Size:**
- Packages: 49 (36 COBOL + 13 JCL)
- Components: ~183 (steps + paragraphs)
- Data Sources: ~144 (datasets + files)
- Dependencies: ~219
- **TOTAL NODES: ~376**

#### SQLite Databases

Four enterprise databases created by `create_sample_dbs.py`:

1. **customer.db**
   - `customers` table (5 records)
   - Indexes on name and state
   - Matches COBOL CUSTOMER-RECORD structure

2. **sales.db**
   - `transactions` table (8 records)
   - `sales_summary` table (reports)
   - FK to customers

3. **inventory.db**
   - `products` table (6 records)
   - `suppliers` table (3 records)
   - `inventory_movements` table (6 records)
   - FKs between tables

4. **employee.db**
   - `employees` table (6 records)
   - `departments` table (4 records)
   - `payroll` table (6 records)
   - Matches COBOL EMPPAY.CBL structure

## Usage

### Generate Sample Data

```bash
# Generate SQLite databases
cd examples/sample_databases
uv run python create_sample_dbs.py

# Generate synthetic mainframe data
cd examples
uv run python generate_mainframe_data.py
```

### Parse Mainframe Environment

```python
from enterprise_assistant.graph.builder import KnowledgeGraphBuilder
from enterprise_assistant.parsers import parser_registry
from pathlib import Path

# Create graph builder
builder = KnowledgeGraphBuilder()

# Parse COBOL programs
cobol_files = Path("examples/sample_mainframe").glob("*.cbl")
for cobol_file in cobol_files:
    parser = parser_registry.get_parser_for_file(cobol_file)
    parsed = parser.parse(cobol_file)
    builder.add_document(parsed)

# Parse JCL jobs
jcl_files = Path("examples/sample_mainframe/jcl").glob("*.jcl")
for jcl_file in jcl_files:
    parser = parser_registry.get_parser_for_file(jcl_file)
    parsed = parser.parse(jcl_file)
    builder.add_document(parsed)

# Get the knowledge graph
graph = builder.get_graph()

print(f"Nodes: {graph.number_of_nodes()}")
print(f"Edges: {graph.number_of_edges()}")
```

### Query with Agent

```python
from enterprise_assistant.agents.enterprise_agent import create_enterprise_agent

# Create agent with graph tools
agent = create_enterprise_agent(
    graph=graph,
    model_provider="openai",  # or "anthropic"
)

# Ask complex questions
response = agent.analyze("What COBOL programs read from CUSTOMER.INPUT.MASTER?")
print(response)

response = agent.analyze("Show me the complete data flow for the DAILYSAL job")
print(response)

response = agent.analyze("If I modify SALES.OUTPUT.SALE001, what components are affected?")
print(response)
```

## Example Queries

### Data Lineage

**Q:** "What are all the upstream sources for the CUSTOMER.OUTPUT dataset?"

**A:** The agent will:
1. Use `graph_query` tool to find the CUSTOMER.OUTPUT dataset
2. Use `trace_lineage` tool with direction="upstream"
3. Return all COBOL programs and JCL steps that write to it

**Q:** "Show me the complete data flow from SALES.INPUT.TRANS to SALES.REPORT"

**A:** The agent will trace both upstream and downstream, showing:
- Input datasets
- COBOL programs that process them
- JCL steps that orchestrate them
- Intermediate datasets
- Final report outputs

### Impact Analysis

**Q:** "If I delete CUSTOMER.INPUT.MASTER, what will break?"

**A:** The agent will:
1. Find all COBOL programs with READ operations on that dataset
2. Find all JCL jobs that reference it
3. Report total impact: X programs, Y jobs affected

**Q:** "Which batch jobs will fail if CUST001 program has a bug?"

**A:** The agent will:
1. Find JCL jobs that execute CUST001
2. Find jobs that depend on CUST001's output datasets
3. Report affected jobs: DAILYCUS, MNTHCUS, etc.

### Dependency Discovery

**Q:** "What must run before the MNTHPAY job?"

**A:** The agent will:
1. Parse MNTHPAY.jcl to find all input datasets
2. Find COBOL programs that produce those datasets
3. Find prerequisite JCL jobs
4. Return execution order

**Q:** "Show me all COBOL programs that call UTIL001"

**A:** The agent will search for `CALL "UTIL001"` statements and return all programs with that dependency

## Graph Structure

### Node Types

1. **Package Nodes** (COBOL programs, JCL jobs)
   - `type`: "package"
   - `document_type`: COBOL_PROGRAM or MAINFRAME_JCL
   - `name`: Program/job name

2. **Component Nodes** (paragraphs, job steps)
   - `type`: "task"
   - `task_type`: "COBOL_PARAGRAPH" or "JCL_STEP"
   - `name`: Paragraph/step name
   - `program`: PGM= value (for JCL steps)

3. **DataSource Nodes** (datasets, files)
   - `type`: "connection"
   - `source_type`: "FILE", "DATABASE", "TAPE"
   - `name`: Dataset name (e.g., CUSTOMER.INPUT.MASTER)

4. **DataEntity Nodes** (COBOL records)
   - `type`: "table"
   - `entity_type`: "RECORD"
   - `columns`: List of field names

### Edge Types

1. **CONTAINS** - Package → Component
2. **USES** - Component → DataSource
3. **PRECEDES** - Component → Component (sequential execution)
4. **READS_FROM** - Component → DataSource
5. **WRITES_TO** - Component → DataSource
6. **CALLS** - Component → Component (COBOL CALL or PERFORM)

### Example Graph Fragment

```
[Package: DAILYSAL (JCL)]
  ├─ CONTAINS → [Component: step_STEP001]
  │   ├─ READS_FROM → [DataSource: SALES.INPUT.TRANS]
  │   └─ WRITES_TO → [DataSource: SALES.OUTPUT.SALE001]
  │
  ├─ CONTAINS → [Component: step_STEP002]
  │   ├─ READS_FROM → [DataSource: SALES.OUTPUT.SALE001]
  │   └─ WRITES_TO → [DataSource: SALES.REPORT.SALE002]
  │
  └─ PRECEDES → [step_STEP001] → [step_STEP002]

[Package: SALE001 (COBOL)]
  ├─ CONTAINS → [Component: 1000-INITIALIZE]
  ├─ CONTAINS → [Component: 2000-PROCESS-RECORDS]
  │   └─ CALLS → [Component: 1000-INITIALIZE] (PERFORM)
  │
  └─ USES → [DataSource: SALES.INPUT.TRANS]
```

## Scalability

For production mainframe environments with thousands of programs:

1. **Use Graph Database Backend**
   - ArangoDB for 10K-100K nodes
   - JanusGraph for 100K-10M nodes
   - See `docs/SCALABILITY.md`

2. **Hierarchical Indexing**
   - Domain → Package → Component
   - O(1) lookups instead of O(n)

3. **Agent Query Planning**
   - Narrow scope with semantic search first
   - Then drill down with graph queries
   - Avoid loading entire graph

4. **Materialized Views**
   - Pre-compute lineage for critical datasets
   - Cache impact analysis for frequently modified programs
   - Invalidate on change

## Future Enhancements

1. **CICS Transaction Parser** - Parse CICS programs and transaction definitions
2. **DB2 DDL Parser** - Extract table schemas from DB2 DDL
3. **Copybook Parser** - Parse COBOL copybooks for shared data structures
4. **IMS Database Parser** - Parse IMS DBD and PSB definitions
5. **VSAM File Metadata** - Extract VSAM catalog information
6. **Cross-Reference Analysis** - Build XREF between all artifacts
7. **Change Impact Prediction** - ML model to predict blast radius of changes

## References

- [COBOL Programming Course](https://github.com/openmainframeproject/cobol-programming-course) - Open Mainframe Project
- [JCL Tutorial](https://www.ibm.com/docs/en/zos) - IBM Z/OS Documentation
- [Enterprise COBOL](https://www.ibm.com/docs/en/cobol-zos) - IBM COBOL Documentation
